# Toxic-Comment-Classifier
A simple toxic comment classifier that classifies the given text into 6 types of toxicity:
1. toxic
2. severe_toxic
3. obscene
4. threat
5. insult
6. identity_hate

Example output:
![image](https://github.com/user-attachments/assets/8068ef2e-6520-46f9-91c9-77faa0b63282)
